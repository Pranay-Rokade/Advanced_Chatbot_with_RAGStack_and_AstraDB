# ğŸ§  Advanced Chatbot with RAGStack and Astra DB Vector Store

## â“ What is RAGStack?

**RAGStack** is a **modular open-source Retrieval-Augmented Generation (RAG) architecture** built by **DataStax** that integrates:

- âš™ï¸ **LangChain** â€“ for LLM orchestration and chaining
- â˜ï¸ **Astra DB** â€“ serverless vector database built on Apache CassandraÂ®
- ğŸ§  **LLMs** â€“ such as OpenAI, Ollama, or Groq for generation
- ğŸ“¦ **Embedding models** â€“ to convert text into semantic vectors

RAGStack enables developers to build scalable, production-grade **RAG pipelines** that combine LLMs with private data for more accurate, grounded, and reliable responses.

---

## ğŸš€ Key Features

- ğŸ”— Integrates **LangChain** with **Astra DB Vector Store**
- ğŸ“¦ Loads and embeds **philosopher quotes dataset** from Hugging Face
- ğŸ§¬ Uses **HuggingFaceEmbeddings** (`all-MiniLM-L6-v2`)
- ğŸ¤– Answers questions based strictly on stored context
- âš¡ Uses **Groq** LLaMA3 inference engine via OpenAI-compatible API
- ğŸ“‘ Supports semantic retrieval and metadata-based storage
- â˜ï¸ Serverless, scalable, production-ready architecture

---

## ğŸ› ï¸ Stack Overview

| Component        | Role                                     |
|------------------|------------------------------------------|
| **Astra DB**      | Serverless, cloud-native vector store    |
| **LangChain**     | RAG pipeline orchestration               |
| **Groq + LLaMA3** | Fast and efficient LLM for answering     |
| **HuggingFace**   | Embedding generation                     |
| **Philosopher Quotes Dataset** | Document source for semantic search |

---

## ğŸ“¦ Setup Instructions

### 1. Install Dependencies

```bash
pip install langchain langchain-community langchain-groq langchain-astra cassio datasets python-dotenv
````

### 2. Add Environment Variables

Create a `.env` file:

```env
ASTRA_DB_API_ENDPOINT=https://your-astra-endpoint.apps.astra.datastax.com
ASTRA_DB_APPLICATION_TOKEN=AstraCS:your_token
GROQ_API_KEY=your_groq_api_key
```

### 3. Run the Script

```bash
python app.py
```

---

## ğŸ“– How It Works

### ğŸ“š Step 1: Load Dataset

```python
philo_dataset = load_dataset("datastax/philosopher-quotes")["train"]
```

### ğŸ§± Step 2: Convert to LangChain Documents

Each quote is wrapped in a `Document` object with metadata (author + tags).

### ğŸ§¬ Step 3: Embedding & Storage

```python
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vstore = AstraDBVectorStore(...)
vstore.add_documents(docs)
```

### ğŸ” Step 4: Retrieval

```python
retriever = vstore.as_retriever(search_kwargs={"k": 3})
```

### ğŸ§  Step 5: RAG Pipeline

```python
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)
```

---

## ğŸ’¬ Example Queries

```python
chain.invoke("What is the importance of controlling emotions?")
```

---

## âœ… What You Learned

* âœ… What **RAGStack** is and how it simplifies RAG development
* âœ… How to integrate **Astra DB** with LangChain
* âœ… How to process, embed, and store documents using metadata
* âœ… How to retrieve and answer context-specific questions using **Groq + LLaMA3**
* âœ… How to build a custom **retrieval pipeline**

---

## ğŸ”® Future Enhancements

* Add Streamlit / FastAPI frontend
* Use LangSmith for debugging and observability
* Add metadata filtering
* Save FAISS/Astra state for reuse

---

## ğŸ™Œ Credits

* [LangChain](https://www.langchain.com/)
* [RAGStack by DataStax](https://docs.datastax.com/en/astra/docs/ragstack/)
* [Groq](https://groq.com/)
* [Hugging Face Datasets](https://huggingface.co/datasets)
* [CassIO](https://github.com/CassioML/cassio)

---

## ğŸš€ Build Scalable, Grounded Chatbots with RAGStack!
